apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaConnector
metadata:
  name: postgres-sink
  namespace: data-dev
  labels:
    strimzi.io/cluster: my-connect
spec:
  class: io.confluent.connect.jdbc.JdbcSinkConnector
  tasksMax: 1
  config:
    # topics: "db2.bank.bnk_contr_fl_sts"
    # table.name.format: "bank.bnk_contr_fl_sts"

    topics: "db2.acc.acc_batch_penalty"
    table.name.format: "acc.acc_batch_penalty"
    # ALTER TABLE acc.acc_batch_penalty ADD PRIMARY KEY (abp_pao_batch_id);

    connection.url: "<INPUT>"
    connection.user: "<INPUT>"
    connection.password: "<INPUT>"

    auto.create: false
    auto.evolve: false

    insert.mode: upsert
    pk.mode: record_key          
    delete.enabled: true

    batch.size: 500
    max.retries: 15
    retry.backoff.ms: 5000

    key.converter: "org.apache.kafka.connect.json.JsonConverter"
    key.converter.schemas.enable: true
    value.converter: "org.apache.kafka.connect.json.JsonConverter"
    value.converter.schemas.enable: true

    transforms: dropTombstones, UniversalDateTimeConverter
    transforms.dropTombstones.type: org.apache.kafka.connect.transforms.Filter
    transforms.dropTombstones.predicate: isTombstone

    predicates: isTombstone
    predicates.isTombstone.type: org.apache.kafka.connect.transforms.predicates.RecordIsTombstone

    transforms.UniversalDateTimeConverter.type: com.example.connect.transforms.UniversalDateTimeConverter
